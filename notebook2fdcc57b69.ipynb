{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras import Model, layers, activations\nimport tensorflow_addons as tfa\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential","metadata":{"_uuid":"5f507d28-c6c1-4cd3-9e95-346fafdf20ca","_cell_guid":"5a0fc0a8-fdc1-447b-a8c2-24ca2b31a683","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:39:55.226328Z","iopub.execute_input":"2021-07-26T09:39:55.226695Z","iopub.status.idle":"2021-07-26T09:39:55.2329Z","shell.execute_reply.started":"2021-07-26T09:39:55.226664Z","shell.execute_reply":"2021-07-26T09:39:55.231631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons","metadata":{"_uuid":"ef488471-8df9-44d5-963e-20a863568eb5","_cell_guid":"61cca7ec-df33-4a37-92a2-2c3b2742ba22","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:40:03.953317Z","iopub.execute_input":"2021-07-26T09:40:03.953897Z","iopub.status.idle":"2021-07-26T09:40:11.202709Z","shell.execute_reply.started":"2021-07-26T09:40:03.953854Z","shell.execute_reply":"2021-07-26T09:40:11.201509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set up the TPU","metadata":{"_uuid":"5e3683b6-fd00-4444-86fc-63e77f27d3fa","_cell_guid":"4849c357-05a9-41b9-b009-bc77de2b2e1e","trusted":true}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    print(\"Running on TPU\",tpu.master())\nexcept:\n    tpu=None\n    print(\"Nope\")\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\nprint(\"Replicas\",strategy.num_replicas_in_sync)","metadata":{"_uuid":"13ae3783-85bf-4b8b-8f68-d79be6ccf6c8","_cell_guid":"c60ffbc3-d907-4671-b17b-00bda8d79487","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:40:15.256893Z","iopub.execute_input":"2021-07-26T09:40:15.257282Z","iopub.status.idle":"2021-07-26T09:40:27.84989Z","shell.execute_reply.started":"2021-07-26T09:40:15.257246Z","shell.execute_reply":"2021-07-26T09:40:27.848904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Model","metadata":{"_uuid":"fe69370e-8f3d-4eee-9310-3cb57731c746","_cell_guid":"74418997-5133-4dfc-bce7-1743a86f1626","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras import Model, layers, activations\nimport tensorflow_addons as tfa\nimport math\n\ndef round_filters(filters, multiplier=1.):\n    divisor = 8\n    min_depth = 8\n    filters *= multiplier\n    min_depth = min_depth or divisor\n    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n    return int(new_filters)\n\n\ndef round_repeats(repeats, multiplier=1.):\n    return int(math.ceil(multiplier * repeats))\n\n\ndef squeeze_and_excite(x, in_channels, out_channels, activation, reduction_ratio=4):\n    x = layers.GlobalAvgPool2D()(x)\n    x = layers.Dense(in_channels // reduction_ratio)(x)\n    x = layers.Activation(activation)(x)\n    x = layers.Dense(out_channels)(x)\n    x = layers.Activation(activations.sigmoid)(x)\n    return x\n\n\ndef fused_mbconv(x, in_channels, out_channels, kernel_size, activation, stride=1, reduction_ratio=4,\n                 expansion=6, dropout=None, drop_connect=.2):\n    shortcut = x\n    expanded = round_filters(in_channels * expansion)\n\n    if expansion != 1:\n        x = layers.Conv2D(expanded, kernel_size, stride, padding=\"same\", use_bias=False)(x)\n        x = layers.BatchNormalization(epsilon=1e-5)(x)\n        x = layers.Activation(activation)(x)\n\n        if (dropout is not None) and (dropout != 0.):\n            x = layers.Dropout(dropout)(x)\n\n    if reduction_ratio is not None:\n        se = squeeze_and_excite(x, in_channels, expanded, activation, reduction_ratio)\n        x = layers.Multiply()([x, se])\n\n    x = layers.Conv2D(out_channels, (1, 1) if expansion != 1 else kernel_size, 1, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    if expansion == 1:\n        x = layers.Activation(activation)(x)\n    if (stride == 1) and (in_channels == out_channels):\n        x = tfa.layers.StochasticDepth(1 - drop_connect)([shortcut, x])\n    return x\n\n\ndef mbconv(x, in_channels, out_channels, kernel_size, activation, stride=1,\n           reduction_ratio=4, expansion=6, dropout=None, drop_connect=.2):\n    shortcut = x\n    expanded = round_filters(in_channels * expansion)\n\n    if expansion != 1:\n        x = layers.Conv2D(expanded, (1, 1), 1, padding=\"same\", use_bias=False)(x)\n        x = layers.BatchNormalization(epsilon=1e-5)(x)\n        x = layers.Activation(activation)(x)\n\n    x = layers.DepthwiseConv2D(kernel_size=kernel_size, strides=stride, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.Activation(activation)(x)\n\n    if (expansion != 1) and (dropout is not None) and (dropout != 0.):\n        x = layers.Dropout(dropout)(x)\n\n    if reduction_ratio is not None:\n        se = squeeze_and_excite(x, in_channels, expanded, activation, reduction_ratio)\n        x = layers.Multiply()([x, se])\n\n    x = layers.Conv2D(out_channels, (1, 1), 1, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    if (stride == 1) and (in_channels == out_channels):\n        x = tfa.layers.StochasticDepth(1 - drop_connect)([shortcut, x])\n    return x\n\n\ndef repeat(x, count, in_channels, out_channels, kernel_size, activation,\n           stride=1, reduction_ratio=None, expansion=6, fused=False, dropout=None, drop_connect=.2):\n    for i in range(count):\n        if fused:\n            x = fused_mbconv(x, in_channels, out_channels, kernel_size,\n                             activation, stride, reduction_ratio, expansion, dropout, drop_connect)\n        else:\n            x = mbconv(x, in_channels, out_channels, kernel_size, activation, stride,\n                       reduction_ratio, expansion, dropout, drop_connect)\n    return x\n\n\ndef stage(x, count, in_channels, out_channels, kernel_size, activation,\n          stride=1, reduction_ratio=None, expansion=6, fused=False, dropout=None, drop_connect=.2):\n    x = repeat(x, count=1, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n               activation=activation, stride=stride, reduction_ratio=reduction_ratio,\n               expansion=expansion, fused=fused, dropout=dropout, drop_connect=drop_connect)\n    x = repeat(x, count=count - 1, in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n               activation=activation, stride=1, reduction_ratio=reduction_ratio,\n               expansion=expansion, fused=fused, dropout=dropout, drop_connect=drop_connect)\n    return x\n\n\ndef base(cfg, num_classes=5, input_tensor=None, activation=activations.swish,\n         width_mult=1., depth_mult=1., conv_dropout_rate=None, dropout_rate=None, drop_connect=.2):\n    inp = input_tensor\n    # stage 0\n    x = layers.Conv2D(cfg[0][4], kernel_size=(3, 3), strides=2, padding=\"same\", use_bias=False)(inp)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.Activation(activation)(x)\n\n    for stage_cfg in cfg:\n        x = stage(x, count=round_repeats(stage_cfg[0], depth_mult),\n                  in_channels=round_filters(stage_cfg[4], width_mult),\n                  out_channels=round_filters(stage_cfg[5], width_mult),\n                  kernel_size=stage_cfg[1], activation=activation, stride=stage_cfg[2],\n                  reduction_ratio=stage_cfg[7], expansion=stage_cfg[3], fused=stage_cfg[6] == 1,\n                  dropout=conv_dropout_rate, drop_connect=drop_connect)\n\n    # final stage\n    x = layers.Conv2D(round_filters(1280, width_mult), (1, 1), strides=1, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.Activation(activation)(x)\n\n    x = layers.GlobalAvgPool2D()(x)\n    if (dropout_rate is not None) and (dropout_rate != 0):\n        x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(num_classes)(x)\n    x = layers.Activation(activations.softmax)(x)\n\n    return Model(inp, x)\n\n\ndef s(in_shape=(224, 224, 3), num_classes=7, input_tensor=None, activation=activations.swish,\n      width_mult=1., depth_mult=1., conv_dropout_rate=None, dropout_rate=None, drop_connect=.2):\n    # each row is a stage\n    # count, kernel size, stride, expansion ratio, in channel, out channel, is fused(1 if true), reduction ratio(None if no se)\n    cfg = [\n        [2, 3, 1, 1, 24, 24, 1, None],\n        [4, 3, 2, 4, 24, 48, 1, None],\n        [4, 3, 2, 4, 48, 64, 1, None],\n        [6, 3, 2, 4, 64, 128, 0, 4],\n        [9, 3, 1, 6, 128, 160, 0, 4],\n        [15, 3, 2, 6, 160, 256, 0, 4],\n    ]\n    input_tensor = layers.Input(in_shape) if input_tensor is None else input_tensor\n    return base(cfg=cfg, num_classes=num_classes, input_tensor=input_tensor, activation=activation,\n                width_mult=width_mult, depth_mult=depth_mult, conv_dropout_rate=conv_dropout_rate,\n                dropout_rate=dropout_rate, drop_connect=drop_connect)\n\ndef xl(in_shape=(224, 224, 3), num_classes=4, input_tensor=None, activation=activations.swish,\n      width_mult=1.0, depth_mult=1., conv_dropout_rate=None, dropout_rate=None, drop_connect=.2):\n    cfg = [\n        [4, 3, 1, 1, 32, 32, 1, None],\n        [8, 3, 2, 4, 32, 64, 1, None],\n        [8, 3, 2, 4, 64, 96, 1, None],\n        [16, 3, 2, 4, 96, 192, 0, 4],\n        [24, 3, 1, 6, 192, 256, 0, 4],\n        [32, 3, 2, 6, 256, 512, 0, 4],\n        [8, 3, 1, 6, 512, 640, 0, 4],\n    ]\n    input_tensor = layers.Input(in_shape) if input_tensor is None else input_tensor\n    return base(cfg=cfg, num_classes=num_classes, input_tensor=input_tensor, activation=activation,\n                width_mult=width_mult, depth_mult=depth_mult, conv_dropout_rate=conv_dropout_rate,\n                dropout_rate=dropout_rate, drop_connect=drop_connect)","metadata":{"_uuid":"42547672-7415-44cd-9ac6-d18bcf67ff8b","_cell_guid":"71406460-d5a9-4dad-89ec-b0c3da890c07","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:40:32.319736Z","iopub.execute_input":"2021-07-26T09:40:32.320123Z","iopub.status.idle":"2021-07-26T09:40:32.366978Z","shell.execute_reply.started":"2021-07-26T09:40:32.320087Z","shell.execute_reply":"2021-07-26T09:40:32.365877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining parameters","metadata":{"_uuid":"60345792-019e-4e43-b874-5739c2341594","_cell_guid":"d2a46d93-d3a5-46a2-8459-0fce718cef77","trusted":true}},{"cell_type":"code","source":"IMAGE_SIZE = [300, 300] # at this size, a GPU will run out of memory. Use the TPU\nEPOCHS = 150\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nNUM_TRAINING_IMAGES = 11932\nNUM_VAL_IMAGES = 3976\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVAL_STEPS = NUM_VAL_IMAGES // BATCH_SIZE","metadata":{"_uuid":"722b605d-55b9-4547-9096-0b859dff4310","_cell_guid":"74f3d9bd-df0d-48da-b544-63e99a6727d2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:41:16.823066Z","iopub.execute_input":"2021-07-26T09:41:16.823475Z","iopub.status.idle":"2021-07-26T09:41:16.829236Z","shell.execute_reply.started":"2021-07-26T09:41:16.823435Z","shell.execute_reply":"2021-07-26T09:41:16.827928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{"_uuid":"7355dcbe-4b88-4184-a049-774e0c3d6166","_cell_guid":"72447b95-cced-4d8a-a300-4ddf9c113a93","trusted":true}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"_uuid":"0c82da62-1e67-44f2-90e0-e7af4dc25760","_cell_guid":"c172e0e4-5e61-4bd9-9b95-10afee6bb60a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:41:19.715471Z","iopub.execute_input":"2021-07-26T09:41:19.715857Z","iopub.status.idle":"2021-07-26T09:41:19.918916Z","shell.execute_reply.started":"2021-07-26T09:41:19.715826Z","shell.execute_reply":"2021-07-26T09:41:19.917609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('Tfrec1')","metadata":{"_uuid":"6a66cadc-2950-4e88-ab22-077b85d279a3","_cell_guid":"96219813-5020-4908-87fe-22bf784527fa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:44:13.343922Z","iopub.execute_input":"2021-07-26T09:44:13.344314Z","iopub.status.idle":"2021-07-26T09:44:13.375261Z","shell.execute_reply.started":"2021-07-26T09:44:13.344282Z","shell.execute_reply":"2021-07-26T09:44:13.373628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])# explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"label\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['label'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n    AUTO = tf.data.experimental.AUTOTUNE\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.prefetch(AUTO)\n    dataset = dataset.map(read_labeled_tfrecord,num_parallel_calls=AUTO) # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    c=1\n    plt.figure(figsize=(20, 4))\n    for features in dataset.take(5):\n        plt.subplot(1,5,c)\n        plt.imshow(features[0].numpy())\n        c+=1\n    plt.show()\n    return dataset\n\ndef get_training_dataset():\n    filenames = tf.io.gfile.glob(GCS_DS_PATH + '/Tfrec1/train/*.tfrec')\n    dataset = load_dataset(filenames, labeled=True, ordered=False)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(NUM_TRAINING_IMAGES)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef get_validation_dataset():\n    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/Tfrec1/val/*.tfrec'), labeled=True, ordered=False)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    return dataset\n\ndef get_test_dataset(ordered=True):\n    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/Tfrec1/test/*.tfrec'), labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset","metadata":{"_uuid":"5d54ae93-3407-4e8d-9762-994e257a9c23","_cell_guid":"e43bf440-6aca-4db1-90b7-8e1212651918","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.500957Z","iopub.status.idle":"2021-07-26T09:37:28.501429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_dataset = get_training_dataset()\nvalidation_dataset = get_validation_dataset()\ntest_dataset = get_test_dataset()","metadata":{"_uuid":"fdaa0ed4-a4c5-4876-8168-764359d4e65a","_cell_guid":"160ada7a-bb3a-445b-ab54-682d8e6e5895","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.502787Z","iopub.status.idle":"2021-07-26T09:37:28.503522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model","metadata":{"_uuid":"0193f05c-36e5-4327-8cb8-8682aa78ca11","_cell_guid":"2d6cd1b5-399e-4f8d-9d71-b645fab1f49d","trusted":true}},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\nwith strategy.scope():\n    model = s(in_shape=(300, 300, 3),num_classes=5, conv_dropout_rate=0.7, dropout_rate=0.7)\n    model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])\n\nhistory = model.fit(training_dataset,steps_per_epoch=STEPS_PER_EPOCH,validation_data=validation_dataset,epochs=EPOCHS,validation_steps=VAL_STEPS)","metadata":{"_uuid":"c8c08827-e0fd-4791-9ab0-f6728e073f2d","_cell_guid":"01a6b34f-1350-4246-8b84-6a8dee1242a6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.504976Z","iopub.status.idle":"2021-07-26T09:37:28.505489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 5])\nplt.legend(loc='lower right')\n\nplt.figure(2)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n\n#test_array = np.array(list(test_dataset.unbatch().take(-1).as_numpy_iterator()), dtype=object)\n#test_x = np.stack(test_array[:,0])\n#test_y = np.stack(test_array[:,1])\n\n# Use the model to predict the labels\n#test_predictions = model.predict(test_x)\n#test_y_pred = np.argmax(test_predictions, axis=1)\n#test_y_true = np.argmax(test_y, axis=1)\n\n# Evaluating model accuracy and logging it as a scalar for TensorBoard hyperparameter visualization.\n#accuracy = sklearn.metrics.accuracy_score(test_y_true, test_y_pred)\n#tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n#logging.info('Test accuracy:{}'.format(accuracy))","metadata":{"_uuid":"c374cd4d-cb16-4c25-acaf-f9d2104c7766","_cell_guid":"31c80c4e-7f61-4b9b-b637-164ffad9a8a1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.50682Z","iopub.status.idle":"2021-07-26T09:37:28.507327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open('./efficientnettrainHistory-goodcdr0.7', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","metadata":{"_uuid":"6f88cc32-1e59-4857-8762-ff87598e814c","_cell_guid":"59be4c9e-2699-4b68-ab85-54d730306516","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.508639Z","iopub.status.idle":"2021-07-26T09:37:28.509156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = pickle.load(open('./efficientnettrainHistory-goodcdr0.7', \"rb\"))","metadata":{"_uuid":"a5f82bc4-d87e-4f2b-845a-029beeb947b3","_cell_guid":"bb14740f-613f-41b3-a9f3-309c766268e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.510522Z","iopub.status.idle":"2021-07-26T09:37:28.511042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(history['loss'], label='loss')\nplt.plot(history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 5])\nplt.legend(loc='lower right')\n\nplt.figure(2)\nplt.plot(history['accuracy'], label='accuracy')\nplt.plot(history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","metadata":{"_uuid":"06854b14-1dca-42ef-ae16-14ebc091ae3a","_cell_guid":"9fa3f911-114e-4719-bdf4-47860ffcdf3d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.51229Z","iopub.status.idle":"2021-07-26T09:37:28.512772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Acne','Eczema','Melanoma','Psoriasis']\nurl = \"https://images.prismic.io/npf-website/37fb7de7-c664-4112-8ae3-d26dcf6a75bb_plaque-psoriasis.jpg?auto=compress,format&rect=0,68,320,184&w=778&h=447\"\npath1 = tf.keras.utils.get_file('Red_sunflower', origin=url)\n\nimg1 = keras.preprocessing.image.load_img(\n    path1, target_size=(300,300)\n)\nimg_array = keras.preprocessing.image.img_to_array(img1)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(np.argmax(score), 100 * np.max(score))\n)","metadata":{"_uuid":"144cbf40-1b1f-4fff-a302-aa2e52174473","_cell_guid":"43052815-fb51-4798-ab42-6da6720254cd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-26T09:37:28.514029Z","iopub.status.idle":"2021-07-26T09:37:28.514522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"55582899-4c8b-4e0d-b2a4-0ea482246e85","_cell_guid":"b8c5872d-348d-46ad-8e65-53b9e62c7142","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}